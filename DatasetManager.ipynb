{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '__main__.nb_Tesis'; '__main__' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-3a1f32a00759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnb_Tesis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnb_ColorTransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '__main__.nb_Tesis'; '__main__' is not a package"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from .nb_Tesis import *\n",
    "from .nb_ColorTransforms import *\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.nb_Tesis import *\n",
    "from exp.nb_ColorTransforms import *\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def add_nevi(df):\n",
    "    df['nevus'] = df.apply(lambda row: 1.0 if row['melanoma'] == 0.0 and row['seborrheic_keratosis'] == 0.0 else 0.0,axis=1)\n",
    "    return df\n",
    "\n",
    "def group_seborrheic_keratosis_or_nevus(df):\n",
    "    df['seborrheic_keratosis_or_nevus'] = df.apply(lambda row: row['seborrheic_keratosis'] or row['nevus'], axis=1)\n",
    "    df.drop(['seborrheic_keratosis','nevus'],axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "path_to_2017_train_raw = Path('ISIC-2017_Training_Data/')\n",
    "path_to_2018_train_raw = Path('ISIC2018_Task3_Training_Input/')\n",
    "path_to_2019_train_raw = Path('ISIC_2019_Training_Input/')\n",
    "\n",
    "path_to_2017_train_gt = Path('ISIC_2017_train_gt.csv')\n",
    "path_to_2018_train_gt = Path('ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv')\n",
    "path_to_2019_train_gt = Path('ISIC_2019_Training_GroundTruth.csv')\n",
    "\n",
    "path_to_2017_valid_raw = Path('ISIC-2017_Validation_Data/')\n",
    "path_to_2017_valid_gt = Path('ISIC_2017_valid_gt.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_to_2018_test_raw = Path('ISIC2018_Task3_Test_Input/')\n",
    "datasets = {\n",
    "    '2017': {\n",
    "        'train_images': path_to_2017_train_raw,\n",
    "        'groundtruth': path_to_2017_train_gt,\n",
    "        'valid_images': path_to_2017_valid_raw,\n",
    "        'valid_groundtruth': path_to_2017_valid_gt\n",
    "    },\n",
    "    '2018': {\n",
    "        'train_images': path_to_2018_train_raw,\n",
    "        'groundtruth': path_to_2018_train_gt,\n",
    "        'test_images': path_to_2018_test_raw\n",
    "    },\n",
    "    '2019': {\n",
    "        'train_images': path_to_2019_train_raw,\n",
    "        'groundtruth': path_to_2019_train_gt,\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import torchvision\n",
    "\n",
    "def resize_one(fn, i, path, size,path_hr, should_crop,transforms=[]):\n",
    "#     print('hereasdasd')\n",
    "    dest = path/fn.relative_to(path_hr)\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    img = open_image(fn)\n",
    "    img = img.apply_tfms(transforms)\n",
    "    img = torchvision.transforms.ToPILImage()(img.data)\n",
    "    targ_sz = resize_to(img, size, use_min=True)\n",
    "    img = img.resize(targ_sz, resample=PIL.Image.BILINEAR).convert('RGB')\n",
    "    img.save(dest, quality=100)\n",
    "    if should_crop:\n",
    "        img = open_image(dest)\n",
    "        crop(img,size)\n",
    "        img.save(dest)\n",
    "\n",
    "\n",
    "class DatasetManager:\n",
    "    def __init__(self,year,min_image_size, amount_of_each_class, year_to_train_for):\n",
    "        self.year = year\n",
    "        self.year_to_train_for = year_to_train_for\n",
    "\n",
    "        self.min_image_size = min_image_size\n",
    "        self.amount_of_each_class = amount_of_each_class\n",
    "        self.df = pd.read_csv(datasets[year]['groundtruth'])\n",
    "        if self.year == '2017':\n",
    "            self.valid_df = pd.read_csv(datasets[year]['valid_groundtruth'])\n",
    "            self.df = pd.concat([self.df,self.valid_df])\n",
    "            add_nevi(self.df)\n",
    "            group_seborrheic_keratosis_or_nevus(self.df)\n",
    "\n",
    "        image_col_name = 'image' if year != '2017' else 'image_id'\n",
    "        self.dfSingleLabel = pd.DataFrame({'image':self.df[image_col_name] })\n",
    "        self.labelcols = self.df.columns[1:len(self.df.columns)]\n",
    "        self.dfSingleLabel['label'] = self.df[list(self.labelcols)].idxmax(axis='columns')\n",
    "        self.classDict = {k:0 for k in self.labelcols }\n",
    "\n",
    "        self.labels_exclusive_for_2019 = ['SCC']\n",
    "    \n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "\n",
    "    def get_dataset_path(self, dataset_type):\n",
    "        if not is_number(self.min_image_size):\n",
    "            return datasets[self.year][dataset_type]\n",
    "        else:\n",
    "            return Path(f'{self.year}_{dataset_type}_resized_to_{self.min_image_size}_picked_{self.amount_of_each_class}_training_for_{self.year_to_train_for or self.year}')\n",
    "\n",
    "    def generate_dataset(self,dataset_type, force=False, should_crop=False,transforms=[]):\n",
    "        if not self.year in ['2017','2018','2019']: raise Exception('We don\\'t have a dataset for that year')\n",
    "        if not dataset_type in ['train_images','valid_images','test_images']: raise Exception('We don\\'t have that dataset type')\n",
    "\n",
    "        new_dataset_folder_name = self.get_dataset_path(dataset_type)\n",
    "        original_images_path = datasets[self.year][dataset_type]\n",
    "        list_of_original_images_paths = ImageList.from_folder(original_images_path).items\n",
    "\n",
    "        if self.amount_of_each_class != 'all':\n",
    "            print(\"Pruning the dataset\")\n",
    "            list_of_original_images_paths = self.prune_image_list(list_of_original_images_paths)\n",
    "        print('here')\n",
    "\n",
    "        sets = [(new_dataset_folder_name, self.min_image_size)]\n",
    "        for p,size in sets:\n",
    "            if not p.exists():\n",
    "                print(f\"resizing to {size} into {p}\")\n",
    "                for idx, image_path in enumerate(list_of_original_images_paths):\n",
    "                    print(f'Processing_{idx}/{len(list_of_original_images_paths)}')\n",
    "                    clear_output(wait=True)\n",
    "                    resize_one(image_path,idx, path=p, size=size, path_hr=original_images_path,should_crop=should_crop,transforms=transforms)\n",
    "                return new_dataset_folder_name\n",
    "            else:\n",
    "                print(f'folder already exists: {new_dataset_folder_name}')\n",
    "\n",
    "\n",
    "    def prune_image_list(self,image_list):\n",
    "        res = []\n",
    "        for image in image_list:\n",
    "            if self.should_image_be_included(image):\n",
    "                res.append(image)\n",
    "        return res\n",
    "\n",
    "\n",
    "    def should_image_be_included(self, image_path):\n",
    "        label = self.get_label_for_image_path(image_path)\n",
    "        if self.year_to_train_for == '2018' and label in self.labels_exclusive_for_2019: return False\n",
    "        if self.classDict[label] >= self.amount_of_each_class: return False\n",
    "        else:\n",
    "            self.classDict[label] = self.classDict[label] + 1\n",
    "            return True\n",
    "\n",
    "    def get_label_for_image_path(self,image_path):\n",
    "        image_name = image_path.name[:-4]\n",
    "        return list(self.dfSingleLabel.loc[self.dfSingleLabel['image']==image_name].label)[0]\n",
    "    \n",
    "    def apply_tfms(self, dataset_type, tfms=[]):\n",
    "        print('asd')\n",
    "        \n",
    "        parallel(self.apply_tfms_to_single_image(tfms), self.get_dataset_path(dataset_type).ls())\n",
    "        \n",
    "    def apply_tfms_to_single_image(self, tfms):\n",
    "        def closure(img_path):\n",
    "            return 'je'\n",
    "        return closure\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DatasetManager('2017', 225,'all','2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-0f0403bfcdf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_images'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorrect_color_max_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-6e6fbef80015>\u001b[0m in \u001b[0;36mgenerate_dataset\u001b[0;34m(self, dataset_type, force, should_crop, transforms)\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Processing_{idx}/{len(list_of_original_images_paths)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mresize_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_hr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_images_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshould_crop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshould_crop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnew_dataset_folder_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-6e6fbef80015>\u001b[0m in \u001b[0;36mresize_one\u001b[0;34m(fn, i, path, size, path_hr, should_crop, transforms)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_tfms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtarg_sz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBILINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \"\"\"\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_pil_image\u001b[0;34m(pic, mode)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input type {} is not supported'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2552\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2554\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2495\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2497\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombytes\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2427\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2429\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2430\u001b[0m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2431\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dm.generate_dataset('train_images',transforms=[correct_color_max_rgb(gamma=1/2.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf 2017_train_images_resized_to_225_picked_all_training_for_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted DatasetManager.ipynb to exp/nb_DatasetManager.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script-Copy1.py DatasetManager.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
